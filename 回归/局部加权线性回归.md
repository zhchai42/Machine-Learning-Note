## 局部加权线性回归 Locally weighted linear regression (LWR)

### 定义

起到对不重要的特征进行筛选的作用。

同样使用线性模型拟合：
$$
y^{(i)}-\theta^{T} x^{(i)}
$$
然而对于不同的数据点，基于一个非负权重$\omega^{(i)}$，衡量它在损失函数中的重要性，并最优化加权距离：
$$
\sum_{i} w^{(i)}\left(y^{(i)}-\theta^{T} x^{(i)}\right)^{2}
$$
最后得到模型 
$$
h_{\theta}(x)=\theta^{T} x
$$

### 权重选取

权重按照如下公式选择
$$
w^{(i)}=\exp \left(-\frac{\left(x^{(i)}-x\right)^{T}\left(x^{(i)}-x\right)}{2 \tau^{2}}\right)
$$
其中$x$为查询点，即需要回归得到$y$的点。

$\tau$被称为带宽参数

当$|x^{(i)}-x|$小（样本离需要查询的点近），权值很大（接近1），反之则小

### 非参数化模型 non-parameteric

模型内的参数是非固定  需要保留训练样本来预测

LWS为非参数化模型（每次确定$w^{(i)}$需要参数$x^{(i)}$）

KNN也是

#### 参数化模型

模型内的参数是固定的，直接用参数做预测，不需要保留训练样本来预测。



