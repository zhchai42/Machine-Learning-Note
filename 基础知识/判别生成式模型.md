## 判别式模型 Discriminative Model

### 定义

学习一个判别函数$h_\theta(x)$，建立$X$到$Y$的直接映射。

判别函数可以是后验概率$P(y|x;\theta)$ 

- Logistic 回归中 $h_{\theta}(x)=g\left(\theta^{T} x\right)$ 作为后验概率的模型。



### 例子

- 感知机 
- 支持向量机
- Logistic 回归
- 线性回归
- SVM
- 条件随机场 CRF
- CART
- boosting

### 1.假设方法

#### 模型直接为预测函数$y=f(x)$

- 感知机
- 支持向量机

#### 模型预测后验概率 $p(y|x)$

- 逻辑斯蒂回归

### 2.学习方法 

#### 对于直接预测函数，优化损失函数$J(\theta)$

$$
\theta^{*}=\arg \max _{\theta} J(\theta)
$$

损失函数

最小均方差 least mean square LMS 

交叉熵 

Maximum Margin

#### 对于预测后验概率，通过MLE MAP估计条件概率

$$
\theta^{*}=\arg \max _{\theta} \sum_{i} \log p\left(y^{(i)} | x^{(i)}\right)
$$

### 3.决策方法

#### 对于直接预测函数，代入即可

$$
y=f(x)
$$

#### 对于估计后验概率

求解使得后验概率最大的$y$
$$
\arg \max _{y} p(y | x)
$$

## 生成式模型 Generative Model

### 定义

对数据点的生成方式感兴趣，即先得到联合概率分布$P(X,Y)$，再基于分布进行决策。

- $P(X|Y)$为对于不同类别的分布建模。
- $P(Y)$为每个类的先验概率。
- 通过贝叶斯规则$p(y | x)=\dfrac{p(x,y)}{p(x)}=\dfrac{p(x | y) p(y)}{p(x)}$推导后验分布。
- 由于$p(x)$是归一化因子，对于确定的$x$，有$p(x)=\int p(x|y)p(y)dy$，所以可以根据$p(x|y)$和$p(y)$建模$p(y|x)$ :

$$
\begin{aligned} \arg \max _{y} p(y | x) &=\arg \max _{y} \frac{p(x | y) p(y)}{p(x)} \\ &=\arg \max _{y} p(x | y) p(y) \end{aligned}
$$

### 例子

- 高斯判别分析  GDA
- 贝叶斯分类器
- LDA
- KNN
- HMM
- 贝叶斯网络
- 马尔科夫随机场
- 深度信念网络 DBN
- 多专家模型
- 隐含狄利克雷分布 LDA

### 1.假设方法

估计数据分布 $p(x, y)=p(y) p(x | y)$ 



### 2.学习方法

通过MLE MAP估计分布
$$
\theta^{*}=\arg \max _{\theta} \sum_{i} \log p\left(x^{(i)}, y^{(i)}\right)
$$

### 3.决策方法

通过贝叶斯公式，根据联合分布，求解使得后验概率最大的$y$
$$
\arg \max _{y} p(y | x)=\arg \max _{y} p(x, y)=\arg \max _{y} p(x | y) p(y)
$$






















